# Staged Data Analytics

Utilizing both on-premises and public cloud environments meets the demands of multi-facility enterprises. Azure Stack offers a rapid, secure and flexible solution for collecting, processing, storing and distributing local and remote data, particularly when security, confidentiality, corporate policy, and regulatory requirements may differ between locations and users.

## Prerequisites

Some preparation is required to build this use case:

-   An installed and functioning Azure Stack (more information can be     found here: [Azure Stack     overview)](https://docs.microsoft.com/en-us/azure/azure-stack/user/azure-stack-storage-overview)

-   An Azure subscription. (Create a [free     account](https://azure.microsoft.com/free/?WT.mc_id=A261C142F))

-   Download and install the [Microsoft Azure Storage     Explorer](http://storageexplorer.com/).

-   The data processed by these functions is not provided. Data must be     generated and available to upload to the Azure Stack storage blob     container.

## Issues and Considerations

[[]{#_Toc520970245 .anchor}]{#_Toc517798085 .anchor}Scalability considerations

Azure functions and storage solutions scale to meet data volume and processing demands. For Azure scalability information and targets, see [Azure scalability documentation](https://docs.microsoft.com/en-us/azure/storage/common/storage-scalability-targets).

[[]{#_Toc520970246 .anchor}]{#_Toc517798086 .anchor}Availability considerations

Storage is the primary availability consideration for this pattern. Connection via fast links is required for large data volume processing and distribution.

[[]{#_Toc520970247 .anchor}]{#_Toc517798087 .anchor}Manageability considerations

Manageability of this solution depends on authoring tools in use and engagement of source control.

[[[[]{#_Toc517437655 .anchor}]{#_Toc517426881 .anchor}]{#_Toc517425903 .anchor}]{#_Toc517798088 .anchor}Staged Data Analytics

## Create the raw data storage blob

The storage account and blob container will hold all original data generated by on-premises activities, including machine and employee activity, facility data, production metrics, and other reporting.

1.  Sign in to the[*Azure Stack     > portal*](https://portal.local.azurestack.external/).

2.  In the Azure stack portal, expand the menu on the left side to open     > the menu of services and choose**All Services**. Scroll down     > to**Storage** and choose**Storage accounts**. In the**Storage     > Accounts**window choose**Add**.

3.  Use the following information for the account:

    a.  Name: **Your choice**

    b.  Deployment model:**Resource Manager**

    c.  Account kind:**Storage (general purpose V1)**

    d.  Location: **West US**

    e.  Replication: **Locally-redundant storage (LRS)**

    f.  Performance:**Standard**

    g.  Secure transfer required: **Disabled**

    h.  Subscription: Choose one

    i.  Resource group: Specify a new resource group or select an         > existing resource group

    j.  Configure virtual networks: **Disabled**

4.  Click**Create**to create the storage account.

![C:\\Users\\JanineT\\AppData\\Local\\Microsoft\\Windows\\INetCache\\Content.MSO\\BFE1C292.tmp](media\azure-stack-solution-staged-data-analytics\image1.png)

1.  Once created, click on the name of the storage account.

2.  In the account blade, under the **BLOB SERVICE** heading, click     > **Containers**.

3.  At the top of the blade, click on**+ Container.**and click     > on**Container**.

![Alt text](media\azure-stack-solution-staged-data-analytics\image2.png){width="3.933333333333333in" height="2.3952996500437447in"}

1.  Name: **Your Choice**

2.  Public access level: **Container** (anonymous read access for     containers and blobs)

3.  Click on**OK**.

Create a New Azure Stack Function to move clean data from Azure Stack to Azure

1.  Create a new Function by clicking on**Functions**, then the**+New     Function**button.

![C:\\Users\\JanineT\\AppData\\Local\\Microsoft\\Windows\\INetCache\\Content.MSO\\7BFF5070.tmp](media\azure-stack-solution-staged-data-analytics\image3.png)

2.  Select**Timer Trigger**.

![C:\\Users\\JanineT\\AppData\\Local\\Microsoft\\Windows\\INetCache\\Content.MSO\\450DBFFE.tmp](media\azure-stack-solution-staged-data-analytics\image4.png)

3.  Select**C\#**as the Language and name the     Function:**upload-to-azure**and set the Schedule to**0 0 \*/1 \*     \* \***which in CRON notation is once an hour.

![C:\\Users\\JanineT\\AppData\\Local\\Microsoft\\Windows\\INetCache\\Content.MSO\\58BC6CBC.tmp](media\azure-stack-solution-staged-data-analytics\image5.png)

4.  Create the function app using the settings specified in the table     below the image.

  **Setting**                                                                                                                            **Suggested value**                     **Description**   -------------------------------------------------------------------------------------------------------------------------------------- --------------------------------------- -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------   **App name**                                                                                                                           Globally unique name                    Name that identifies your new function app. Valid characters are a-z, 0-9, and -.   **Subscription**                                                                                                                       Your subscription                       The subscription under which this new function app is created.   [**Resource Group**](https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-overview)                            myResourceGroup                         Name for the new resource group in which to create your function app.   **OS**                                                                                                                                 Windows                                 Serverless hosting is currently only available when running on Windows.   [**Hosting plan**](https://docs.microsoft.com/en-us/azure/azure-functions/functions-scale)                                             Consumption plan                        Hosting plan that defines how resources are allocated to your function app. In the default **Consumption Plan**, resources are added dynamically as required by your functions. In this [serverless](https://azure.microsoft.com/overview/serverless-computing/) hosting, you only pay for the time your functions run.   **Location**                                                                                                                           Region nearest you                      Choose a [region](https://azure.microsoft.com/regions/) near you or near other services your functions access.   [**Storage account**](https://docs.microsoft.com/en-us/azure/storage/common/storage-create-storage-account#create-a-storage-account)   &lt;storage account created above&gt;   Name of the new storage account used by your function app. Storage account names must be between 3 and 24 characters in length and may contain numbers and lowercase letters only. You can also use an existing account.

**Example:**

![Define new function app settings](media\azure-stack-solution-staged-data-analytics\image6.png)

4.  Select **Create** to provision and deploy the function app.

5.  Select the Notification icon in the upper-right corner of the portal     > and watch for the **Deployment succeeded** message.

![Define new function app settings](media\azure-stack-solution-staged-data-analytics\image7.png)

4.  Select **Go to resource** to view new function app.

![Function app successfully created.](media\azure-stack-solution-staged-data-analytics\image8.png)

## Create a Blob storage triggered function

1.  Expand the function app and click the **+** button next to     **Functions**. If this is the first function in the function app,     select **Custom function**. This displays the complete set of     function templates.

> ![Functions quickstart page in the Azure > portal](media\azure-stack-solution-staged-data-analytics\image9.png)

1.  In the search field, type blob and then choose the desired language     for the Blob storage trigger template.

> ![Choose the Blob storage trigger > template.](media\azure-stack-solution-staged-data-analytics\image10.png)

1.  Use the settings as specified in the table below:

  **Setting**                      **Suggested value**                            **Description**   -------------------------------- ---------------------------------------------- -----------------------------------------------------------------------------------------------------------------------   **Name**                         Unique in your function app                    Name of this blob triggered function.   **Path**                         &lt;path from the storage location above&gt;   Location in Blob storage being monitored. The file name of the blob is passed in the binding as the *name* parameter.   **Storage account connection**   Function App Connection                        You can use the storage account connection already being used by your function app or create a new one.

> **Example:** > > ![Create the Blob storage triggered > function.](media\azure-stack-solution-staged-data-analytics\image11.png)

1.  Click **Create** to create the function.

Test the function -----------------

1.  In the Azure portal, browse to the function. Expand the **Logs** at     the bottom of the page and ensure log streaming is not paused.

2.  Open Storage Explorer and connect to the storage account created at     the beginning of this section.

3.  Expand the storage account, **Blob containers**, and **the blob you     created earlier**. Click **Upload** and then **Upload files.**

> ![Upload a file to the blob > container.](media\azure-stack-solution-staged-data-analyticsimage12.png)

1.  In the Upload files dialog box, click the Files field. Browse to a     file on a local computer, such as an image file, select it and click     **Open** and then **Upload**.

2.  Go back to function logs and verify the blob has been read.

> **Example:**

![View message in the logs.](media\azure-stack-solution-staged-data-analytics\image13.png)

## Create an Azure Stack storage account containing a blob and a queue

### Storage Blob  Data archiving

This storage account will house two containers. These containers are one blob used to hold archive data, and a queue used for the processing of data assigned for main office distribution.

Use the steps and settings outlined above to create another storage account and blob container as our archive storage.

### Storage Queue  Filtered Data holding

1.  Use the steps and settings outlined above to access the new storage     > account.

2.  In the **Storage Account** Overview section click on **Queue.**

3.  Click the **+ Queue** and fill-in **Name** field and fill-in a name     > for the new queue.

4.  Click **OK.**

> ![Alt text](media\azure-stack-solution-staged-data-analytics\image14.png)

![Alt text](media\azure-stack-solution-staged-data-analytics\image15.png)

## Create a queue triggered function

1.  Use the steps in the above function creation section to create an     > additional Azure Stack function with a queue trigger instead of a     > blob trigger.

2.  Use the settings as specified in the table below:

  **Setting**                      **Suggested value**                            **Description**   -------------------------------- ---------------------------------------------- -------------------------------------------------------------------------------------------------------------------   **Name**                         Unique in your function app                    Name of this queue triggered function.   **Path**                         &lt;path from the storage location above&gt;   Location in storage being monitored. The file name of the queue is passed in the binding as the *name* parameter.   **Storage account connection**   Function App Connection                        You can use the storage account connection already being used by your function app or create a new one.

1.  Click **Create** to create the function.

## Test the queue triggered function

1.  In the Azure portal, browse to the function. Expand the **Logs** at     > the bottom of the page and ensure log streaming is not paused.

2.  Open Storage Explorer and connect to the storage account created at     > the beginning of this section.

3.  Expand the storage account, **Blob containers**, and **the blob you     > created earlier**. Click **Upload** and then **Upload files.**

![Upload a file to the blob container.](media\azure-stack-solution-staged-data-analytics\image12.png)

1.  In the Upload files dialog box, click the Files field. Browse to a     > file on a local computer, such as an image file, select it and     > click **Open** and then **Upload**.

2.  Go back to function logs and verify the blob has been read.

> **Example:**

![View message in the logs.](media\azure-stack-solution-staged-data-analytics\image13.png)

## Securely stored and accessed compliant data

Global enterprise data is securely stored, processed, distributed and accessed via Azure and Azure Stack Staged Data Analytics and custom endpoint directives. Remote office employee and machinery activities, facility data, and business metrics are continually compiled, stored, tested for compliance, and distributed according to company policy and regional regulation. 